{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_spiderman_noway_home.csv\n",
      "Cleaned data saved to D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_doctorstrange.csv\n",
      "Cleaned data saved to D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_thor_love_thunder.csv\n",
      "Cleaned data saved to D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_black_panther.csv\n",
      "Cleaned data saved to D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_antman.csv\n",
      "Cleaned data saved to D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_deadpool_wolverine.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_save_file(file_path, output_path):\n",
    "    \n",
    "    columns_to_drop = [\n",
    "        'ipc-rating-star--maxRating', 'ipc-title-link-wrapper href', 'ipc-title__text', \n",
    "        'ipc-html-content-inner-div', 'ipc-voting__label__text', 'ipc-voting__dot-separator', \n",
    "        'ipc-voting__label__count', 'ipc-voting__label__count 2', 'ipc-link href', \n",
    "        'ipc-inline-list__item', 'ipc-btn__text'\n",
    "    ]\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "files = [\n",
    "    \"D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Black panther.csv\",\n",
    "    \"D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/AntMan.csv\",\n",
    "    \"D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Deadpool&Wolverine.csv\",\n",
    "    \"D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/doctorstrange.csv\",\n",
    "    \"D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/spiderman noway home.csv\",\n",
    "    \"D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/thor love&thunder.csv\"\n",
    "]\n",
    "output_paths = [\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_spiderman_noway_home.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_doctorstrange.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_thor_love_thunder.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_black_panther.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_antman.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_deadpool_wolverine.csv'\n",
    "]\n",
    "\n",
    "for file_path, output_path in zip(files, output_paths):\n",
    "    clean_and_save_file(file_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    cleaned spiderman noway home  cleaned doctorstrange  \\\n",
      "007Waffles                                   6.0                    NaN   \n",
      "11ovz11                                     10.0                    NaN   \n",
      "18Buddha                                     NaN                    9.0   \n",
      "3xHCCH                                       9.0                    NaN   \n",
      "80sHorror                                    NaN                    NaN   \n",
      "...                                          ...                    ...   \n",
      "zkzuber                                      NaN                    NaN   \n",
      "zorba-36271                                  NaN                    NaN   \n",
      "ztpbrmhw                                     NaN                    NaN   \n",
      "zwjonas                                      NaN                    NaN   \n",
      "zzzxxxcccvvv-43202                           1.0                    1.0   \n",
      "\n",
      "                    cleaned thor love thunder  cleaned black panther  \\\n",
      "007Waffles                                NaN                    3.0   \n",
      "11ovz11                                   NaN                    NaN   \n",
      "18Buddha                                  NaN                    NaN   \n",
      "3xHCCH                                    NaN                    NaN   \n",
      "80sHorror                                10.0                    NaN   \n",
      "...                                       ...                    ...   \n",
      "zkzuber                                   NaN                    NaN   \n",
      "zorba-36271                               NaN                    NaN   \n",
      "ztpbrmhw                                  7.0                    NaN   \n",
      "zwjonas                                   9.0                    NaN   \n",
      "zzzxxxcccvvv-43202                        NaN                    NaN   \n",
      "\n",
      "                    cleaned antman  cleaned deadpool wolverine  \n",
      "007Waffles                     4.0                         NaN  \n",
      "11ovz11                        NaN                         NaN  \n",
      "18Buddha                       NaN                         8.0  \n",
      "3xHCCH                         NaN                         NaN  \n",
      "80sHorror                      NaN                         NaN  \n",
      "...                            ...                         ...  \n",
      "zkzuber                        5.0                         NaN  \n",
      "zorba-36271                    NaN                         7.0  \n",
      "ztpbrmhw                       NaN                         NaN  \n",
      "zwjonas                        NaN                         NaN  \n",
      "zzzxxxcccvvv-43202             NaN                         NaN  \n",
      "\n",
      "[1610 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "def find_similar_name_groups(file_paths, threshold=70):\n",
    "    all_names = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'names' in df.columns:\n",
    "            all_names.extend(df['names'].dropna().unique())\n",
    "        elif 'ipc-link' in df.columns:\n",
    "            all_names.extend(df['ipc-link'].dropna().unique())\n",
    "    \n",
    "    all_names = sorted(set(all_names))\n",
    "    similar_name_groups = []\n",
    "    matched = set()\n",
    "    \n",
    "    for name in all_names:\n",
    "        if name not in matched:\n",
    "            group = [match[0] for match in process.extract(name, all_names, scorer=fuzz.token_sort_ratio) if match[1] >= threshold]\n",
    "            matched.update(group)\n",
    "            similar_name_groups.append(group)\n",
    "    \n",
    "    return similar_name_groups\n",
    "\n",
    "def build_user_ratings_matrix(file_paths, similar_name_groups):\n",
    "    user_ratings = pd.DataFrame(index=[\"/\".join(group) for group in similar_name_groups])\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        movie_title = file_path.split('/')[-1].replace('.csv', '').replace('_', ' ') \n",
    "        \n",
    "        if 'names' in df.columns:\n",
    "            df_filtered = df[['names', 'ipc-rating-star--rating']].rename(columns={'names': 'Name', 'ipc-rating-star--rating': 'Rating'})\n",
    "        elif 'ipc-link' in df.columns:\n",
    "            df_filtered = df[['ipc-link', 'ipc-rating-star--rating']].rename(columns={'ipc-link': 'Name', 'ipc-rating-star--rating': 'Rating'})\n",
    "        \n",
    "        ratings = {}\n",
    "        for group in similar_name_groups:\n",
    "            group_ratings = df_filtered[df_filtered['Name'].isin(group)]['Rating']\n",
    "            if not group_ratings.empty:\n",
    "                ratings[\"/\".join(group)] = group_ratings.min()\n",
    "        \n",
    "        user_ratings[movie_title] = pd.Series(ratings)\n",
    "    \n",
    "    return user_ratings\n",
    "\n",
    "file_paths = [\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_spiderman_noway_home.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_doctorstrange.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_thor_love_thunder.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_black_panther.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_antman.csv',\n",
    "    'D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/cleaned_deadpool_wolverine.csv'\n",
    "]\n",
    "\n",
    "similar_name_groups = find_similar_name_groups(file_paths, threshold=70)\n",
    "\n",
    "user_ratings_matrix = build_user_ratings_matrix(file_paths, similar_name_groups)\n",
    "\n",
    "print(user_ratings_matrix)\n",
    "user_ratings_matrix.to_csv('D:/Galala UNi/4th Year/AIE425Intelligent recommender systems/Assignments/Assignment1/Cleaned DataSets/user_ratings_matrix.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Based CF Predictions (Cosine) for tkdlifemagazine: {'spiderman no way home': 7.18279160508015, 'deadpool wolverine': 5.830992894285834}\n",
      "User-Based CF Predictions (Pearson) for tkdlifemagazine: {'spiderman no way home': 3.9144297644201482, 'deadpool wolverine': 5.23899996112657}\n",
      "Item-Based CF Predictions (Adjusted Cosine) for tkdlifemagazine: {'spiderman no way home': 8.356072607196047, 'deadpool wolverine': 7.334821301788396}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "data = {\n",
    "    'spiderman no way home': [6, 7, np.nan, 7, 9],\n",
    "    'doctor strange': [10, 6, 4, 5, np.nan],\n",
    "    'thor love thunder': [9, np.nan, 8, 8, 5],\n",
    "    'black panther': [7, 6, 6, 7, 10],\n",
    "    'antman': [8, 9, 8, 10, 7],\n",
    "    'deadpool wolverine': [7, 5, np.nan, 6, 5]\n",
    "}\n",
    "user_matrix = pd.DataFrame(data, index=['BrnzReviews', 'AvionPrince16', 'tkdlifemagazine', 'Entertainmentsp', 'Carycomic'])\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return 1 - cosine(vec1, vec2)\n",
    "\n",
    "def pearson_similarity(vec1, vec2):\n",
    "    mask = ~np.isnan(vec1) & ~np.isnan(vec2)\n",
    "    if mask.sum() == 0:\n",
    "        return 0  \n",
    "    return pearsonr(vec1[mask], vec2[mask])[0]\n",
    "\n",
    "def user_based_cf(matrix, target_user, similarity_measure='cosine'):\n",
    "    user_similarities = pd.DataFrame(index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    for user1 in matrix.index:\n",
    "        for user2 in matrix.index:\n",
    "            if user1 != user2:\n",
    "                if similarity_measure == 'cosine':\n",
    "                    user_similarities.loc[user1, user2] = cosine_similarity(\n",
    "                        matrix.loc[user1].fillna(0), matrix.loc[user2].fillna(0))\n",
    "                elif similarity_measure == 'pearson':\n",
    "                    user_similarities.loc[user1, user2] = pearson_similarity(\n",
    "                        matrix.loc[user1], matrix.loc[user2])\n",
    "    \n",
    "    predictions = {}\n",
    "    for item in matrix.columns[matrix.loc[target_user].isna()]:\n",
    "        sim_sum = 0\n",
    "        weighted_sum = 0\n",
    "        for other_user in matrix.index:\n",
    "            if other_user != target_user and not np.isnan(matrix.loc[other_user, item]):\n",
    "                similarity = user_similarities.loc[target_user, other_user]\n",
    "                rating = matrix.loc[other_user, item]\n",
    "                sim_sum += similarity\n",
    "                weighted_sum += similarity * rating\n",
    "        predictions[item] = weighted_sum / sim_sum if sim_sum != 0 else np.nan\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def adjusted_cosine_similarity(matrix, item1, item2):\n",
    "    mean_centered_matrix = matrix.sub(matrix.mean(axis=1), axis=0)\n",
    "    return cosine_similarity(mean_centered_matrix[item1].fillna(0), mean_centered_matrix[item2].fillna(0))\n",
    "\n",
    "def item_based_cf(matrix, target_user):\n",
    "    item_similarities = pd.DataFrame(index=matrix.columns, columns=matrix.columns)\n",
    "    \n",
    "    for item1 in matrix.columns:\n",
    "        for item2 in matrix.columns:\n",
    "            if item1 != item2:\n",
    "                item_similarities.loc[item1, item2] = adjusted_cosine_similarity(matrix, item1, item2)\n",
    "    \n",
    "    predictions = {}\n",
    "    for item in matrix.columns[matrix.loc[target_user].isna()]:\n",
    "        sim_sum = 0\n",
    "        weighted_sum = 0\n",
    "        for other_item in matrix.columns:\n",
    "            if other_item != item and not np.isnan(matrix.loc[target_user, other_item]):\n",
    "                similarity = item_similarities.loc[item, other_item]\n",
    "                rating = matrix.loc[target_user, other_item]\n",
    "                sim_sum += similarity\n",
    "                weighted_sum += similarity * rating\n",
    "        predictions[item] = weighted_sum / sim_sum if sim_sum != 0 else np.nan\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "target_user = 'tkdlifemagazine'\n",
    "user_based_predictions_cosine = user_based_cf(user_matrix, target_user, similarity_measure='cosine')\n",
    "user_based_predictions_pearson = user_based_cf(user_matrix, target_user, similarity_measure='pearson')\n",
    "item_based_predictions_adjusted_cosine = item_based_cf(user_matrix, target_user)\n",
    "\n",
    "print(\"User-Based CF Predictions (Cosine) for tkdlifemagazine:\", user_based_predictions_cosine)\n",
    "print(\"User-Based CF Predictions (Pearson) for tkdlifemagazine:\", user_based_predictions_pearson)\n",
    "print(\"Item-Based CF Predictions (Adjusted Cosine) for tkdlifemagazine:\", item_based_predictions_adjusted_cosine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
